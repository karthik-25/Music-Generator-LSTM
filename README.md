# Music Generation with Deep Learning

## Project Overview
This project explores the fascinating intersection of artificial intelligence and music by employing deep learning techniques to generate musical sequences. Utilizing Long Short-Term Memory (LSTM) networks, a type of recurrent neural network (RNN) optimized for learning long-term dependencies, the goal was to model and generate musical notes based on a corpus of music. For this project, a collection of piano MIDI files were used from the [MAESTRO dataset](https://magenta.tensorflow.org/datasets/maestro).

This project follows the foundational steps laid out in the TensorFlow tutorial: [Generate music with an RNN](https://www.tensorflow.org/tutorials/audio/music_generation#setup). It also incorporates additional explorations and customizations to enhance the model's performance and creativity in music generation.

## Objectives

* **Model Training:** Train an LSTM model to capture patterns in musical sequences.
* **Music Generation:** Use the model to create new sequences with controlled randomness.
* **Evaluation and Experimentation:** Assess performance and tweak hyperparameters to refine the output.

## Technologies
* **TensorFlow & Keras:** For model architecture and training.
* **NumPy & Pandas:** For data manipulation and structuring.
* **Matplotlib:** For visualizing training progress.
